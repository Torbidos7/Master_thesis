\documentclass[../main.tex]{subfiles}
\usepackage[english]{babel}
\graphicspath{{\subfix{../images}}}
\begin{document}
The data analyzed were natural light-reflected images acquired during clinical practice.
These image show high heterogeneity, presenting different resolutions, light conditions, and backgrounds. 
The most simple segmentation solutions, described in Chapter \ref{chap:segmentation}, could not be applied due to non-standardized condition during image acquisition. Thus the choice of using CNNs was reinforced by the TL and ASSL training strategies which compensate the lack of annotated data, universally known as the main drawback for deep learning models.

The aim of this work was to develop a model for the automatic segmentation of pet-wound images starting with no manually labelled sample and using only TL and ASSL training strategy. 
The combination of the two training strategies proved their effectiveness in generating large amounts of annotated samples with the minimal human intervention. 
This procedure speeds up the validation procedure by clinicians and it is proven to be a viable solution in medical analyses.
This work may represent a starting point for the development of automate wound management in veterinary medicine for clinical and research activities. More over the robustness of the TL procedure, combined with the ASSL one, could become a viable and time-efficient solution for low labelled set of data.

We found as optimal deep learning model for the ASSL training strategy the EfficientNet-b3 U-Net model, comparing its performances with the lighter MobileNet-v2 U-Net one.
We also numerically proved that the complexity of wound segmentation does not require complex deep learning models, showing compatible performances between the EfficientNet-b3 U-Net and the MobileNet-v2 U-Net architectures when trained on larger set of annotated images. 
The inclusion of TL components in the ASSL pipeline, indeed, strengthens the generalization capabilities of the trained models.

The results obtained in this paper stands as a reliable solution to perform a correct wound image segmentation.  
With this work we aim to minimize the labeling effort of the clinicians, requiring no starting manual annotation at all. Furthermore The MobileNet-v2 U-Net performances suggest that the future direction of this field could focus on implementations of smartphone-based technologies. 

\end{document}